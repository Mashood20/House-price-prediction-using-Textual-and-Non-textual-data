{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a988a3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c2ab5-f79b-47fb-83f2-f87a05abcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import certifi as cert\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scraping_scripts import scrape_type, scrape_address, scrape_location, scrape_price, scrape_shared_ownership, scrape_specs_list, scrape_description_list, scrape_description_text, scrape_listing_data, scrape_travel_times_list, scrape_average_sale_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd284b73",
   "metadata": {},
   "source": [
    "### Define baseurl and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ce3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.zoopla.co.uk'\n",
    "user_agent = 'Mozilla/5.0 (compatible; GrapeshotCrawler/2.0; +http://www.grapeshot.co.uk/crawler.php)'\n",
    "headers = {\n",
    "    'User-Agent': user_agent\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e470b",
   "metadata": {},
   "source": [
    "### Get listing urls, listing ids, and shared ownership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9390274-09e0-495d-a6f0-3075831afbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_ids_shared_ownerships = []\n",
    "\n",
    "step = 50000\n",
    "for price in tqdm(range(150000, 200000, step)):\n",
    "    for page_n in tqdm(range(1, 2)):\n",
    "        \n",
    "        url = f'https://www.zoopla.co.uk/for-sale/property/london/?price_max={price+step}&price_min={price}&q=London&results_sort=newest_listings&search_source=for-sale&pn={page_n}'\n",
    "        r = req.get(url, headers=headers, verify=cert.where(), timeout=None)\n",
    "        \n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        propertylist = soup.find_all('div', class_='_1lw0o5c0')\n",
    "\n",
    "        for property in propertylist:\n",
    "            for url in property.find_all('a'):\n",
    "                href = url['href']\n",
    "                listingId = href[-9:-1]\n",
    "                shared_ownership = scrape_shared_ownership.run(url)\n",
    "                urls_ids_shared_ownerships.append((baseurl + href, listingId, shared_ownership))\n",
    "\n",
    "print(str(len(urls_ids_shared_ownerships)) + \" listings have been found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65abd357",
   "metadata": {},
   "source": [
    "#### Download urls_ids_shared_ownership list as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_location = '../data/urls_ids_shared_ownerships_2.json'\n",
    "with open(json_location, 'w') as json_file:\n",
    "    json.dump(urls_ids_shared_ownerships, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4aa212",
   "metadata": {},
   "source": [
    "#### Load urls_ids_shared_ownerships.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_location, 'r') as json_file:\n",
    "    urls_ids_shared_ownerships = json.load(json_file)\n",
    "urls_ids_shared_ownerships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b426262",
   "metadata": {},
   "source": [
    "### Scrape and store listing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9881007",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_dicts = []\n",
    "session = req.Session()\n",
    "retry = Retry(connect=3, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)\n",
    "\n",
    "for url, listingId, shared_ownership in tqdm(urls_ids_shared_ownerships):\n",
    "    \n",
    "    try:\n",
    "        r = session.get(url, headers=headers, verify=cert.where(), timeout=None)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        property_dict = {\n",
    "            'url': url,\n",
    "            'type': scrape_type.run(soup),\n",
    "            'address': scrape_address.run(soup),\n",
    "            'location': scrape_location.run(soup),\n",
    "            'price': scrape_price.run(soup),\n",
    "            'average_sale_price': scrape_average_sale_price.run(listingId),\n",
    "            'shared_ownership': shared_ownership,\n",
    "            'specs_list': scrape_specs_list.run(soup),\n",
    "            'description_list': scrape_description_list.run(soup),\n",
    "            'description_text': scrape_description_text.run(soup),\n",
    "            'listing_data': scrape_listing_data.run(listingId),\n",
    "            'travel_times_list': scrape_travel_times_list.run(soup)\n",
    "        }\n",
    "\n",
    "        property_dicts.append(property_dict)\n",
    "    \n",
    "    except req.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc33c8d",
   "metadata": {},
   "source": [
    "### Create Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(property_dicts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2252a",
   "metadata": {},
   "source": [
    "### Save data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/scraped_data_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
